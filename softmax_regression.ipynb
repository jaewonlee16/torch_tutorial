{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Some Information about MyDataset\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.x = torch.FloatTensor([[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]])\n",
    "\n",
    "        self.y = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0])\n",
    "        #self.y_onehot = torch.zeros(8, 3)\n",
    "        #self.y_onehot.scatter_(1, self.y.unsqueeze(1), 1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor(self.x[index])\n",
    "        y = torch.tensor(self.y[index], dtype = torch.long)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxClassifierModule(nn.Module):\n",
    "    \"\"\"Some Information about SoftMaxClassifierModule\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SoftMaxClassifierModule, self).__init__()\n",
    "        self.linear = nn.Linear(4, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftMaxClassifierModule()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_888/3916825992.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.y[index], dtype = torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0/1000, batch 0, prediction tensor([[ 2.1575,  0.6679, -1.2908],\n",
      "        [ 1.0823, -0.7838, -0.3176]]), loss 1.216212511062622\n",
      "epoch    0/1000, batch 1, prediction tensor([[ 0.4108, -0.4138, -0.3503],\n",
      "        [ 2.0113,  0.1423, -1.2989]]), loss 1.7247424125671387\n",
      "epoch    0/1000, batch 2, prediction tensor([[ 1.3841,  1.4131, -0.9972],\n",
      "        [ 1.8151,  1.4362, -1.4324]]), loss 0.633833646774292\n",
      "epoch    0/1000, batch 3, prediction tensor([[ 0.7466, -0.0705, -0.2288],\n",
      "        [ 0.4183,  0.1929, -0.2233]]), loss 1.529341220855713\n",
      "epoch   20/1000, batch 0, prediction tensor([[-0.5176, -0.0667,  0.2310],\n",
      "        [ 1.3724,  0.7817, -0.3541]]), loss 0.967697262763977\n",
      "epoch   20/1000, batch 1, prediction tensor([[-0.6016,  0.5280,  0.5210],\n",
      "        [ 0.9334,  1.1527, -0.5514]]), loss 0.875906229019165\n",
      "epoch   20/1000, batch 2, prediction tensor([[ 0.2241, -0.0247,  0.1886],\n",
      "        [ 1.4577,  0.9320, -0.5707]]), loss 0.7945561408996582\n",
      "epoch   20/1000, batch 3, prediction tensor([[-0.9305,  0.1028,  0.8087],\n",
      "        [ 0.9299,  0.4882, -0.5634]]), loss 1.142322301864624\n",
      "epoch   40/1000, batch 0, prediction tensor([[ 1.5096,  1.1993, -0.8899],\n",
      "        [-0.8332,  0.0827,  0.3973]]), loss 0.6526205539703369\n",
      "epoch   40/1000, batch 1, prediction tensor([[-1.5173,  0.6005,  0.8976],\n",
      "        [ 1.6576,  0.4464, -0.3040]]), loss 1.2387422323226929\n",
      "epoch   40/1000, batch 2, prediction tensor([[ 0.4867,  1.3769, -1.0090],\n",
      "        [ 1.1237,  1.2889, -0.8779]]), loss 0.6232229471206665\n",
      "epoch   40/1000, batch 3, prediction tensor([[ 0.1363, -0.0171,  0.2688],\n",
      "        [-0.9105,  0.8135,  0.5443]]), loss 0.9494924545288086\n",
      "epoch   60/1000, batch 0, prediction tensor([[-1.2478,  0.9186,  0.7766],\n",
      "        [ 0.0023, -0.0667,  0.4523]]), loss 0.8147171139717102\n",
      "epoch   60/1000, batch 1, prediction tensor([[ 1.3587,  0.6988, -0.2576],\n",
      "        [-1.0480,  0.1146,  0.5801]]), loss 0.9003839492797852\n",
      "epoch   60/1000, batch 2, prediction tensor([[ 0.8657,  1.3149, -0.6459],\n",
      "        [ 0.2291,  1.5061, -0.8806]]), loss 0.6702857613563538\n",
      "epoch   60/1000, batch 3, prediction tensor([[ 1.4148,  1.3453, -0.9410],\n",
      "        [-2.1194,  1.0235,  1.0767]]), loss 0.7238842248916626\n",
      "epoch   80/1000, batch 0, prediction tensor([[ 0.6961,  1.3448, -1.1862],\n",
      "        [ 1.9091,  1.1356, -1.2257]]), loss 0.44008302688598633\n",
      "epoch   80/1000, batch 1, prediction tensor([[-0.0145, -0.1896,  0.5921],\n",
      "        [-2.0626,  1.0160,  1.0275]]), loss 0.7080360651016235\n",
      "epoch   80/1000, batch 2, prediction tensor([[ 1.5849,  1.0375, -1.0877],\n",
      "        [ 1.7127,  0.6404, -0.5530]]), loss 0.9701851606369019\n",
      "epoch   80/1000, batch 3, prediction tensor([[-1.3758,  1.0238,  0.7992],\n",
      "        [-1.0962,  0.2299,  0.5130]]), loss 0.7652977705001831\n",
      "epoch  100/1000, batch 0, prediction tensor([[ 0.7009,  1.4836, -1.3299],\n",
      "        [-2.3001,  1.1594,  1.1216]]), loss 0.5535763502120972\n",
      "epoch  100/1000, batch 1, prediction tensor([[ 1.7916,  1.5912, -1.5638],\n",
      "        [-1.5786,  1.1277,  0.8982]]), loss 0.7339867353439331\n",
      "epoch  100/1000, batch 2, prediction tensor([[ 1.7113,  0.8978, -1.0744],\n",
      "        [-1.1232,  0.1051,  0.6649]]), loss 0.480929434299469\n",
      "epoch  100/1000, batch 3, prediction tensor([[-0.0611, -0.2838,  0.7328],\n",
      "        [ 1.9594,  0.2624, -0.4218]]), loss 1.2679647207260132\n",
      "epoch  120/1000, batch 0, prediction tensor([[-2.5787,  1.3349,  1.2248],\n",
      "        [-0.2905, -0.1745,  0.8529]]), loss 0.583440899848938\n",
      "epoch  120/1000, batch 1, prediction tensor([[ 1.6836,  1.6782, -1.5428],\n",
      "        [ 1.3180,  1.3903, -1.1737]]), loss 0.7396010756492615\n",
      "epoch  120/1000, batch 2, prediction tensor([[ 1.9609,  0.3608, -0.5217],\n",
      "        [-1.4717,  0.8827,  1.0363]]), loss 1.256701111793518\n",
      "epoch  120/1000, batch 3, prediction tensor([[-1.2670,  0.1565,  0.7573],\n",
      "        [ 0.7267,  1.5991, -1.4711]]), loss 0.4502298831939697\n",
      "epoch  140/1000, batch 0, prediction tensor([[ 1.6598,  1.0572, -1.1824],\n",
      "        [ 1.6547,  0.5897, -0.4444]]), loss 0.9609795808792114\n",
      "epoch  140/1000, batch 1, prediction tensor([[-2.5862,  1.3743,  1.1928],\n",
      "        [ 1.9264,  1.5399, -1.6473]]), loss 0.5759341716766357\n",
      "epoch  140/1000, batch 2, prediction tensor([[-1.6705,  1.0781,  1.0397],\n",
      "        [-0.2897, -0.2129,  0.8905]]), loss 0.61934894323349\n",
      "epoch  140/1000, batch 3, prediction tensor([[-1.2705,  0.1147,  0.8025],\n",
      "        [ 0.9116,  1.5662, -1.6232]]), loss 0.46644335985183716\n",
      "epoch  160/1000, batch 0, prediction tensor([[ 1.3945,  1.4318, -1.2916],\n",
      "        [-1.4694,  0.2572,  0.8590]]), loss 0.621393084526062\n",
      "epoch  160/1000, batch 1, prediction tensor([[-0.3990, -0.2644,  1.0513],\n",
      "        [ 2.1266,  1.3439, -1.6515]]), loss 0.39969512820243835\n",
      "epoch  160/1000, batch 2, prediction tensor([[ 1.0096,  1.5033, -1.6583],\n",
      "        [-1.7654,  0.9296,  1.2831]]), loss 0.5309338569641113\n",
      "epoch  160/1000, batch 3, prediction tensor([[ 1.6619,  0.4461, -0.3081],\n",
      "        [-2.6245,  1.1903,  1.4150]]), loss 1.1996045112609863\n",
      "epoch  180/1000, batch 0, prediction tensor([[ 1.9042,  0.9296, -1.2991],\n",
      "        [-1.3557,  0.0614,  0.9410]]), loss 0.3824794292449951\n",
      "epoch  180/1000, batch 1, prediction tensor([[ 2.5847,  0.9221, -1.6878],\n",
      "        [ 1.1712,  1.4208, -1.7373]]), loss 0.3925233483314514\n",
      "epoch  180/1000, batch 2, prediction tensor([[ 1.8969,  0.3121, -0.4090],\n",
      "        [-2.5528,  1.1580,  1.3757]]), loss 1.3347582817077637\n",
      "epoch  180/1000, batch 3, prediction tensor([[-0.5024, -0.2050,  1.0954],\n",
      "        [-2.0125,  1.2526,  1.2072]]), loss 0.5619617700576782\n",
      "epoch  200/1000, batch 0, prediction tensor([[-2.0399,  1.1676,  1.3196],\n",
      "        [ 1.6298,  0.7136, -0.5434]]), loss 0.9846974611282349\n",
      "epoch  200/1000, batch 1, prediction tensor([[ 1.4084,  1.5159, -1.3897],\n",
      "        [ 1.8477,  1.8396, -1.8682]]), loss 0.7390053868293762\n",
      "epoch  200/1000, batch 2, prediction tensor([[ 1.1861,  1.5770, -1.9085],\n",
      "        [-2.5986,  1.2281,  1.3514]]), loss 0.6508395671844482\n",
      "epoch  200/1000, batch 3, prediction tensor([[-1.4362,  0.2037,  0.8792],\n",
      "        [-0.5152, -0.2675,  1.1706]]), loss 0.413657009601593\n",
      "epoch  220/1000, batch 0, prediction tensor([[ 0.8868,  1.9950, -2.0271],\n",
      "        [ 2.0860,  1.7341, -2.0011]]), loss 0.42052948474884033\n",
      "epoch  220/1000, batch 1, prediction tensor([[-1.5261,  0.1785,  0.9944],\n",
      "        [-2.1417,  1.1919,  1.3971]]), loss 0.5160799026489258\n",
      "epoch  220/1000, batch 2, prediction tensor([[-0.6128, -0.3370,  1.3378],\n",
      "        [ 1.5997,  0.5572, -0.3569]]), loss 0.8643498420715332\n",
      "epoch  220/1000, batch 3, prediction tensor([[-3.1126,  1.5947,  1.4988],\n",
      "        [ 1.3961,  1.4723, -1.3337]]), loss 0.7069449424743652\n",
      "epoch  240/1000, batch 0, prediction tensor([[-2.1092,  1.1020,  1.4545],\n",
      "        [ 1.2104,  1.7600, -2.1156]]), loss 0.5087876319885254\n",
      "epoch  240/1000, batch 1, prediction tensor([[-2.9096,  1.4205,  1.4700],\n",
      "        [ 2.3859,  1.4027, -1.9696]]), loss 0.525845468044281\n",
      "epoch  240/1000, batch 2, prediction tensor([[-0.6225, -0.3395,  1.3499],\n",
      "        [ 2.0263,  1.1455, -1.6371]]), loss 0.32260334491729736\n",
      "epoch  240/1000, batch 3, prediction tensor([[ 1.9580,  0.4159, -0.5740],\n",
      "        [-1.4299,  0.0712,  1.0054]]), loss 1.0959073305130005\n",
      "epoch  260/1000, batch 0, prediction tensor([[-2.8732,  1.5339,  1.3202],\n",
      "        [ 1.2316,  1.8906, -2.2675]]), loss 0.5129586458206177\n",
      "epoch  260/1000, batch 1, prediction tensor([[-1.5916,  0.2828,  0.9556],\n",
      "        [-0.7395, -0.2551,  1.3826]]), loss 0.36804312467575073\n",
      "epoch  260/1000, batch 2, prediction tensor([[ 1.5720,  0.8781, -0.6501],\n",
      "        [ 2.3606,  1.7889, -2.3305]]), loss 0.8111661076545715\n",
      "epoch  260/1000, batch 3, prediction tensor([[ 1.7282,  1.5956, -1.7891],\n",
      "        [-2.3230,  1.3883,  1.3819]]), loss 0.6766372323036194\n",
      "epoch  280/1000, batch 0, prediction tensor([[ 1.7149,  1.5179, -1.6981],\n",
      "        [ 2.2508,  1.8525, -2.2843]]), loss 0.5687689781188965\n",
      "epoch  280/1000, batch 1, prediction tensor([[-1.4921,  0.0473,  1.0915],\n",
      "        [-2.7871,  1.3789,  1.3891]]), loss 0.5309215784072876\n",
      "epoch  280/1000, batch 2, prediction tensor([[-0.7205, -0.3635,  1.4719],\n",
      "        [-2.1755,  1.1794,  1.4433]]), loss 0.41244786977767944\n",
      "epoch  280/1000, batch 3, prediction tensor([[ 1.4141,  1.7393, -2.2988],\n",
      "        [ 1.8907,  0.4675, -0.5582]]), loss 1.130125641822815\n",
      "epoch  300/1000, batch 0, prediction tensor([[ 1.8580,  1.4659, -1.7892],\n",
      "        [ 1.5366,  0.8771, -0.6137]]), loss 0.8409348726272583\n",
      "epoch  300/1000, batch 1, prediction tensor([[-3.1467,  1.7767,  1.3509],\n",
      "        [-2.4620,  1.3798,  1.5294]]), loss 0.569075345993042\n",
      "epoch  300/1000, batch 2, prediction tensor([[-0.8948, -0.2628,  1.5456],\n",
      "        [ 1.1276,  2.1855, -2.4584]]), loss 0.26456189155578613\n",
      "epoch  300/1000, batch 3, prediction tensor([[ 2.1874,  2.0814, -2.4498],\n",
      "        [-1.7403,  0.2964,  1.0906]]), loss 0.5296713709831238\n",
      "epoch  320/1000, batch 0, prediction tensor([[ 1.2416,  2.0674, -2.4543],\n",
      "        [-2.4844,  1.3146,  1.6170]]), loss 0.46676105260849\n",
      "epoch  320/1000, batch 1, prediction tensor([[ 2.3702,  1.7712, -2.3224],\n",
      "        [ 1.4610,  0.8487, -0.5097]]), loss 0.7878683805465698\n",
      "epoch  320/1000, batch 2, prediction tensor([[-3.2741,  1.7469,  1.5081],\n",
      "        [ 1.7195,  1.5702, -1.7550]]), loss 0.611156702041626\n",
      "epoch  320/1000, batch 3, prediction tensor([[-0.9009, -0.3153,  1.6042],\n",
      "        [-1.6693,  0.2053,  1.1108]]), loss 0.2942323684692383\n",
      "epoch  340/1000, batch 0, prediction tensor([[ 2.0932,  1.3148, -1.8732],\n",
      "        [-1.6702,  0.1338,  1.1831]]), loss 0.36639848351478577\n",
      "epoch  340/1000, batch 1, prediction tensor([[-0.8895, -0.4218,  1.6992],\n",
      "        [-3.0034,  1.4829,  1.5014]]), loss 0.44307005405426025\n",
      "epoch  340/1000, batch 2, prediction tensor([[ 2.9080,  1.5608, -2.6498],\n",
      "        [ 1.4885,  1.9894, -2.6232]]), loss 0.3570229709148407\n",
      "epoch  340/1000, batch 3, prediction tensor([[ 1.8507,  0.6677, -0.7185],\n",
      "        [-2.4396,  1.3086,  1.5783]]), loss 1.0423460006713867\n",
      "epoch  360/1000, batch 0, prediction tensor([[-1.0593, -0.2856,  1.7329],\n",
      "        [-2.7054,  1.4848,  1.6679]]), loss 0.39504504203796387\n",
      "epoch  360/1000, batch 1, prediction tensor([[ 1.1734,  2.1926, -2.5113],\n",
      "        [-1.8134,  0.2076,  1.2526]]), loss 0.3250184655189514\n",
      "epoch  360/1000, batch 2, prediction tensor([[-3.4562,  1.8341,  1.6030],\n",
      "        [ 1.6774,  1.6329, -1.7756]]), loss 0.6371141672134399\n",
      "epoch  360/1000, batch 3, prediction tensor([[ 2.5650,  1.8699, -2.6160],\n",
      "        [ 1.5444,  0.9025, -0.6470]]), loss 0.7719670534133911\n",
      "epoch  380/1000, batch 0, prediction tensor([[ 1.2763,  2.3135, -2.7351],\n",
      "        [-1.0867, -0.2987,  1.7733]]), loss 0.23816603422164917\n",
      "epoch  380/1000, batch 1, prediction tensor([[ 2.4039,  2.1794, -2.7643],\n",
      "        [-2.7883,  1.5507,  1.6849]]), loss 0.6123504638671875\n",
      "epoch  380/1000, batch 2, prediction tensor([[ 1.6470,  0.7732, -0.6203],\n",
      "        [-3.2570,  1.7080,  1.5299]]), loss 0.9525051116943359\n",
      "epoch  380/1000, batch 3, prediction tensor([[ 1.7441,  1.9265, -2.1359],\n",
      "        [-1.8647,  0.3485,  1.1629]]), loss 0.5987607836723328\n",
      "epoch  400/1000, batch 0, prediction tensor([[-2.8128,  1.5479,  1.7122],\n",
      "        [ 2.4905,  2.1836, -2.8551]]), loss 0.5871912240982056\n",
      "epoch  400/1000, batch 1, prediction tensor([[-3.2588,  1.7089,  1.5308],\n",
      "        [ 1.6585,  0.7969, -0.6554]]), loss 0.9465534687042236\n",
      "epoch  400/1000, batch 2, prediction tensor([[ 1.2316,  2.4817, -2.8587],\n",
      "        [-1.8704,  0.3388,  1.1783]]), loss 0.3236026465892792\n",
      "epoch  400/1000, batch 3, prediction tensor([[ 1.7029,  1.9749, -2.1431],\n",
      "        [-1.1973, -0.2394,  1.8246]]), loss 0.5046714544296265\n",
      "epoch  420/1000, batch 0, prediction tensor([[ 1.8025,  1.8784, -2.1462],\n",
      "        [-1.2211, -0.2764,  1.8854]]), loss 0.4446752071380615\n",
      "epoch  420/1000, batch 1, prediction tensor([[-2.7905,  1.4623,  1.7754],\n",
      "        [-3.3644,  1.8752,  1.4701]]), loss 0.53446364402771\n",
      "epoch  420/1000, batch 2, prediction tensor([[ 1.4275,  2.2781, -2.8509],\n",
      "        [-1.8113,  0.2206,  1.2374]]), loss 0.3514242172241211\n",
      "epoch  420/1000, batch 3, prediction tensor([[ 2.6004,  2.0629, -2.8442],\n",
      "        [ 1.4698,  1.0404, -0.7103]]), loss 0.729881763458252\n",
      "epoch  440/1000, batch 0, prediction tensor([[-1.2057, -0.3563,  1.9499],\n",
      "        [ 1.4267,  2.2637, -2.8357]]), loss 0.2485038936138153\n",
      "epoch  440/1000, batch 1, prediction tensor([[-1.8984,  0.2390,  1.3062],\n",
      "        [ 1.4475,  1.0480, -0.6955]]), loss 0.6529812812805176\n",
      "epoch  440/1000, batch 2, prediction tensor([[ 1.6587,  1.9759, -2.0999],\n",
      "        [-3.0765,  1.6499,  1.8739]]), loss 0.7326680421829224\n",
      "epoch  440/1000, batch 3, prediction tensor([[ 2.6341,  1.9015, -2.7166],\n",
      "        [-3.5104,  1.8125,  1.6788]]), loss 0.513407826423645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  460/1000, batch 0, prediction tensor([[ 2.9208,  1.8647, -2.9665],\n",
      "        [-1.2245, -0.3820,  1.9944]]), loss 0.212651327252388\n",
      "epoch  460/1000, batch 1, prediction tensor([[ 1.8149,  0.7099, -0.7249],\n",
      "        [-1.7731,  0.1012,  1.3186]]), loss 0.8711825013160706\n",
      "epoch  460/1000, batch 2, prediction tensor([[ 2.0037,  1.6935, -2.1626],\n",
      "        [ 1.3998,  2.3303, -2.8755]]), loss 0.4476441740989685\n",
      "epoch  460/1000, batch 3, prediction tensor([[-3.4668,  1.8821,  1.5656],\n",
      "        [-2.9218,  1.4759,  1.8932]]), loss 0.5305480360984802\n",
      "epoch  480/1000, batch 0, prediction tensor([[-3.5772,  2.0401,  1.5180],\n",
      "        [-1.3160, -0.3297,  2.0336]]), loss 0.294807106256485\n",
      "epoch  480/1000, batch 1, prediction tensor([[-3.0308,  1.6783,  1.7998],\n",
      "        [ 1.4219,  2.5234, -3.0906]]), loss 0.4640759825706482\n",
      "epoch  480/1000, batch 2, prediction tensor([[ 1.9386,  1.8649, -2.2688],\n",
      "        [-1.9632,  0.2932,  1.3168]]), loss 0.4994594156742096\n",
      "epoch  480/1000, batch 3, prediction tensor([[ 2.9094,  1.9101, -3.0005],\n",
      "        [ 1.6265,  0.9013, -0.7278]]), loss 0.748772144317627\n",
      "epoch  500/1000, batch 0, prediction tensor([[-3.0440,  1.5351,  1.9562],\n",
      "        [ 1.5611,  0.9929, -0.7540]]), loss 0.7934269905090332\n",
      "epoch  500/1000, batch 1, prediction tensor([[-3.7494,  2.0646,  1.6656],\n",
      "        [-1.4151, -0.3063,  2.1093]]), loss 0.31372812390327454\n",
      "epoch  500/1000, batch 2, prediction tensor([[ 1.3002,  2.5907, -3.0363],\n",
      "        [ 2.5029,  2.4497, -3.1336]]), loss 0.45728376507759094\n",
      "epoch  500/1000, batch 3, prediction tensor([[ 2.0701,  1.7909, -2.3263],\n",
      "        [-1.9421,  0.2508,  1.3381]]), loss 0.4442702531814575\n",
      "epoch  520/1000, batch 0, prediction tensor([[ 3.0798,  1.9710, -3.2318],\n",
      "        [ 2.3331,  1.6026, -2.4010]]), loss 0.34279149770736694\n",
      "epoch  520/1000, batch 1, prediction tensor([[-3.2912,  1.7515,  1.5206],\n",
      "        [ 2.0241,  0.6287, -0.8528]]), loss 1.1244125366210938\n",
      "epoch  520/1000, batch 2, prediction tensor([[-1.8934,  0.2836,  1.2566],\n",
      "        [ 1.6214,  2.5009, -3.2677]]), loss 0.3502683937549591\n",
      "epoch  520/1000, batch 3, prediction tensor([[-3.1181,  1.7151,  1.8502],\n",
      "        [-1.3885, -0.3079,  2.0843]]), loss 0.3735607862472534\n",
      "epoch  540/1000, batch 0, prediction tensor([[-3.0955,  1.5552,  1.9875],\n",
      "        [ 1.6665,  0.9708, -0.8374]]), loss 0.8286921977996826\n",
      "epoch  540/1000, batch 1, prediction tensor([[ 2.6929,  2.2955, -3.1694],\n",
      "        [-1.4753, -0.3208,  2.1840]]), loss 0.3089164197444916\n",
      "epoch  540/1000, batch 2, prediction tensor([[ 2.2488,  1.6128, -2.3269],\n",
      "        [-3.5949,  1.9223,  1.6535]]), loss 0.5008105039596558\n",
      "epoch  540/1000, batch 3, prediction tensor([[-1.8599,  0.1635,  1.3432],\n",
      "        [ 1.7560,  2.2925, -3.1939]]), loss 0.3808506727218628\n",
      "epoch  560/1000, batch 0, prediction tensor([[-3.3184,  1.7432,  2.0224],\n",
      "        [ 1.4240,  2.6106, -3.1799]]), loss 0.4173523187637329\n",
      "epoch  560/1000, batch 1, prediction tensor([[ 2.5921,  2.4109, -3.1840],\n",
      "        [-3.9018,  2.1954,  1.6873]]), loss 0.5403782725334167\n",
      "epoch  560/1000, batch 2, prediction tensor([[ 1.5245,  1.1452, -0.8697],\n",
      "        [-1.9855,  0.2499,  1.3824]]), loss 0.6292462944984436\n",
      "epoch  560/1000, batch 3, prediction tensor([[-1.5435, -0.2788,  2.2102],\n",
      "        [ 1.8939,  2.0937, -2.4529]]), loss 0.4524940550327301\n",
      "epoch  580/1000, batch 0, prediction tensor([[-1.5011, -0.3636,  2.2526],\n",
      "        [ 2.2586,  1.7608, -2.4847]]), loss 0.28620654344558716\n",
      "epoch  580/1000, batch 1, prediction tensor([[ 3.2574,  1.9082, -3.3466],\n",
      "        [-3.5806,  1.9517,  1.6098]]), loss 0.38539931178092957\n",
      "epoch  580/1000, batch 2, prediction tensor([[-1.8649,  0.1649,  1.3467],\n",
      "        [ 1.8685,  2.3261, -3.3400]]), loss 0.3951699733734131\n",
      "epoch  580/1000, batch 3, prediction tensor([[-3.1922,  1.6436,  1.9959],\n",
      "        [ 1.7378,  0.9932, -0.9311]]), loss 0.8574270009994507\n",
      "epoch  600/1000, batch 0, prediction tensor([[ 1.8401,  2.2987, -3.2842],\n",
      "        [-1.9070,  0.1349,  1.4188]]), loss 0.3822227120399475\n",
      "epoch  600/1000, batch 1, prediction tensor([[ 3.1984,  2.0090, -3.3884],\n",
      "        [ 1.6963,  0.9531, -0.8494]]), loss 0.725445568561554\n",
      "epoch  600/1000, batch 2, prediction tensor([[ 2.2233,  1.8431, -2.5317],\n",
      "        [-3.3591,  1.7148,  2.0915]]), loss 0.5255478620529175\n",
      "epoch  600/1000, batch 3, prediction tensor([[-1.5000, -0.4306,  2.3185],\n",
      "        [-3.6678,  1.9354,  1.7133]]), loss 0.3363707661628723\n",
      "epoch  620/1000, batch 0, prediction tensor([[-1.6002, -0.3424,  2.3305],\n",
      "        [ 1.4697,  1.2249, -0.8946]]), loss 0.4797058403491974\n",
      "epoch  620/1000, batch 1, prediction tensor([[-4.0463,  2.4156,  1.6116],\n",
      "        [-3.5563,  1.8919,  2.1117]]), loss 0.4810510575771332\n",
      "epoch  620/1000, batch 2, prediction tensor([[-2.1593,  0.3657,  1.4403],\n",
      "        [ 2.6348,  2.6759, -3.4917]]), loss 0.5144481062889099\n",
      "epoch  620/1000, batch 3, prediction tensor([[ 2.2405,  1.8286, -2.5344],\n",
      "        [ 1.6150,  2.5165, -3.2768]]), loss 0.42811307311058044\n",
      "epoch  640/1000, batch 0, prediction tensor([[-3.9187,  2.2651,  1.6345],\n",
      "        [-2.0809,  0.2683,  1.4593]]), loss 0.3577451705932617\n",
      "epoch  640/1000, batch 1, prediction tensor([[ 1.4833,  1.2891, -0.9725],\n",
      "        [ 1.5908,  2.6854, -3.4215]]), loss 0.5656474828720093\n",
      "epoch  640/1000, batch 2, prediction tensor([[-3.6663,  2.0275,  2.0861],\n",
      "        [ 2.5713,  2.8958, -3.6482]]), loss 0.7676101922988892\n",
      "epoch  640/1000, batch 3, prediction tensor([[ 2.2277,  1.8955, -2.5885],\n",
      "        [-1.6370, -0.3535,  2.3784]]), loss 0.31268301606178284\n",
      "epoch  660/1000, batch 0, prediction tensor([[-4.0700,  2.4056,  1.6453],\n",
      "        [ 1.3420,  1.3840, -0.9260]]), loss 0.5531842112541199\n",
      "epoch  660/1000, batch 1, prediction tensor([[ 1.8540,  2.4766, -2.7959],\n",
      "        [-1.7683, -0.2179,  2.3741]]), loss 0.5711668133735657\n",
      "epoch  660/1000, batch 2, prediction tensor([[ 1.5850,  2.7761, -3.5064],\n",
      "        [ 2.9910,  2.5684, -3.7403]]), loss 0.38576021790504456\n",
      "epoch  660/1000, batch 3, prediction tensor([[-2.0618,  0.2969,  1.4117],\n",
      "        [-3.4950,  1.8466,  2.0956]]), loss 0.44260430335998535\n",
      "epoch  680/1000, batch 0, prediction tensor([[ 3.1372,  2.3551, -3.6733],\n",
      "        [ 1.6699,  2.6430, -3.4583]]), loss 0.3498268723487854\n",
      "epoch  680/1000, batch 1, prediction tensor([[ 2.4220,  1.8357, -2.7230],\n",
      "        [-3.5382,  1.7922,  2.1933]]), loss 0.48031818866729736\n",
      "epoch  680/1000, batch 2, prediction tensor([[-3.7931,  2.0428,  1.7312],\n",
      "        [-2.0008,  0.1224,  1.5252]]), loss 0.3971591591835022\n",
      "epoch  680/1000, batch 3, prediction tensor([[ 1.8157,  0.9514, -0.9672],\n",
      "        [-1.6263, -0.4246,  2.4389]]), loss 0.6650588512420654\n",
      "epoch  700/1000, batch 0, prediction tensor([[-1.7374, -0.3704,  2.4956],\n",
      "        [-4.0078,  2.2676,  1.7211]]), loss 0.26346471905708313\n",
      "epoch  700/1000, batch 1, prediction tensor([[ 2.3322,  2.0014, -2.7989],\n",
      "        [ 1.5207,  1.2890, -1.0097]]), loss 0.7019655704498291\n",
      "epoch  700/1000, batch 2, prediction tensor([[ 1.6574,  2.7495, -3.5522],\n",
      "        [-2.1309,  0.3180,  1.4596]]), loss 0.29425668716430664\n",
      "epoch  700/1000, batch 3, prediction tensor([[ 2.9711,  2.5889, -3.7410],\n",
      "        [-3.7020,  1.9353,  2.2140]]), loss 0.5429590940475464\n",
      "epoch  720/1000, batch 0, prediction tensor([[-2.1213,  0.2616,  1.5064],\n",
      "        [-3.6618,  1.8504,  2.2587]]), loss 0.39242690801620483\n",
      "epoch  720/1000, batch 1, prediction tensor([[-1.7679, -0.3948,  2.5506],\n",
      "        [ 2.3841,  1.7941, -2.6436]]), loss 0.254536896944046\n",
      "epoch  720/1000, batch 2, prediction tensor([[ 1.7341,  0.9167, -0.8509],\n",
      "        [-3.8963,  2.0687,  1.8085]]), loss 0.9035286903381348\n",
      "epoch  720/1000, batch 3, prediction tensor([[ 1.6312,  2.7752, -3.5517],\n",
      "        [ 3.0427,  2.5773, -3.8010]]), loss 0.3829194903373718\n",
      "epoch  740/1000, batch 0, prediction tensor([[-3.6932,  1.8224,  2.3180],\n",
      "        [ 1.5880,  1.1776, -0.9657]]), loss 0.7211092710494995\n",
      "epoch  740/1000, batch 1, prediction tensor([[ 1.5704,  2.7456, -3.4614],\n",
      "        [-1.8689, -0.3214,  2.5782]]), loss 0.1676248461008072\n",
      "epoch  740/1000, batch 2, prediction tensor([[ 2.8349,  2.6611, -3.6770],\n",
      "        [-2.2619,  0.3246,  1.5840]]), loss 0.43859028816223145\n",
      "epoch  740/1000, batch 3, prediction tensor([[-4.0958,  2.2342,  1.8425],\n",
      "        [ 2.3416,  1.8518, -2.6588]]), loss 0.499740868806839\n",
      "epoch  760/1000, batch 0, prediction tensor([[ 1.6566,  1.1582, -1.0149],\n",
      "        [ 1.8552,  2.6024, -3.6030]]), loss 0.7021781206130981\n",
      "epoch  760/1000, batch 1, prediction tensor([[-1.9176, -0.2739,  2.5794],\n",
      "        [ 2.9027,  2.8109, -3.8946]]), loss 0.3576957881450653\n",
      "epoch  760/1000, batch 2, prediction tensor([[ 2.4089,  2.0034, -2.8777],\n",
      "        [-4.0949,  2.3939,  1.6819]]), loss 0.45703405141830444\n",
      "epoch  760/1000, batch 3, prediction tensor([[-3.6641,  1.8790,  2.2323],\n",
      "        [-2.0788,  0.2544,  1.4711]]), loss 0.4074976444244385\n",
      "epoch  780/1000, batch 0, prediction tensor([[-2.1165,  0.1965,  1.5668],\n",
      "        [ 1.8868,  2.5715, -3.6036]]), loss 0.3279411792755127\n",
      "epoch  780/1000, batch 1, prediction tensor([[ 3.3124,  2.3291, -3.8224],\n",
      "        [ 1.5609,  1.1944, -0.9554]]), loss 0.6290172934532166\n",
      "epoch  780/1000, batch 2, prediction tensor([[ 2.3323,  2.0431, -2.8406],\n",
      "        [-1.9030, -0.3433,  2.6342]]), loss 0.31099796295166016\n",
      "epoch  780/1000, batch 3, prediction tensor([[-4.0481,  2.2615,  1.7674],\n",
      "        [-3.7580,  1.8098,  2.3955]]), loss 0.46068859100341797\n",
      "epoch  800/1000, batch 0, prediction tensor([[ 3.3879,  2.3782, -3.9471],\n",
      "        [-1.8982, -0.3713,  2.6574]]), loss 0.18417289853096008\n",
      "epoch  800/1000, batch 1, prediction tensor([[ 1.7519,  1.0699, -1.0218],\n",
      "        [-3.7595,  1.8140,  2.3928]]), loss 0.7891143560409546\n",
      "epoch  800/1000, batch 2, prediction tensor([[-4.2165,  2.3866,  1.8107],\n",
      "        [-2.2177,  0.2556,  1.6089]]), loss 0.34696412086486816\n",
      "epoch  800/1000, batch 3, prediction tensor([[ 2.3446,  2.1133, -2.9232],\n",
      "        [ 1.7257,  2.7928, -3.6638]]), loss 0.4419308602809906\n",
      "epoch  820/1000, batch 0, prediction tensor([[-2.2250,  0.2959,  1.5759],\n",
      "        [ 1.4864,  1.3598, -1.0463]]), loss 0.531221866607666\n",
      "epoch  820/1000, batch 1, prediction tensor([[ 1.5691,  2.9636, -3.6780],\n",
      "        [ 2.9680,  2.8251, -3.9741]]), loss 0.42366695404052734\n",
      "epoch  820/1000, batch 2, prediction tensor([[ 2.3617,  2.1085, -2.9355],\n",
      "        [-4.2798,  2.5014,  1.7593]]), loss 0.483765184879303\n",
      "epoch  820/1000, batch 3, prediction tensor([[-1.9144, -0.3661,  2.6684],\n",
      "        [-3.8615,  1.9580,  2.3508]]), loss 0.2868857979774475\n",
      "epoch  840/1000, batch 0, prediction tensor([[-1.9460, -0.4038,  2.7377],\n",
      "        [ 1.6682,  1.1389, -1.0071]]), loss 0.5429932475090027\n",
      "epoch  840/1000, batch 1, prediction tensor([[ 2.3120,  2.1722, -2.9495],\n",
      "        [ 1.7025,  2.8485, -3.6964]]), loss 0.4527800977230072\n",
      "epoch  840/1000, batch 2, prediction tensor([[ 3.3568,  2.4628, -4.0006],\n",
      "        [-2.2214,  0.2588,  1.6093]]), loss 0.2954265773296356\n",
      "epoch  840/1000, batch 3, prediction tensor([[-4.1291,  2.2873,  1.8226],\n",
      "        [-3.8893,  1.8397,  2.4968]]), loss 0.45363712310791016\n",
      "epoch  860/1000, batch 0, prediction tensor([[ 2.3260,  2.1748, -2.9661],\n",
      "        [-2.0527, -0.3304,  2.7710]]), loss 0.3373670279979706\n",
      "epoch  860/1000, batch 1, prediction tensor([[-4.2367,  2.4115,  1.8061],\n",
      "        [-3.9906,  1.9322,  2.5056]]), loss 0.4421953558921814\n",
      "epoch  860/1000, batch 2, prediction tensor([[ 1.6114,  1.2272, -1.0386],\n",
      "        [ 1.8742,  2.7250, -3.7445]]), loss 0.650751531124115\n",
      "epoch  860/1000, batch 3, prediction tensor([[-2.3571,  0.4000,  1.6038],\n",
      "        [ 3.0037,  2.8953, -4.0799]]), loss 0.45891904830932617\n",
      "epoch  880/1000, batch 0, prediction tensor([[-4.0796,  2.0157,  2.5112],\n",
      "        [ 2.4964,  2.0660, -3.0277]]), loss 0.48997923731803894\n",
      "epoch  880/1000, batch 1, prediction tensor([[ 3.6506,  2.1590, -3.9906],\n",
      "        [ 1.9841,  2.5627, -3.6921]]), loss 0.3248419463634491\n",
      "epoch  880/1000, batch 2, prediction tensor([[-4.2202,  2.3228,  1.8782],\n",
      "        [-2.1942,  0.1711,  1.6698]]), loss 0.3574540615081787\n",
      "epoch  880/1000, batch 3, prediction tensor([[-2.0053, -0.4036,  2.7969],\n",
      "        [ 1.6959,  1.1611, -1.0570]]), loss 0.5415557026863098\n",
      "epoch  900/1000, batch 0, prediction tensor([[-2.2957,  0.3057,  1.6368],\n",
      "        [ 3.3341,  2.6243, -4.1394]]), loss 0.32506808638572693\n",
      "epoch  900/1000, batch 1, prediction tensor([[-4.0659,  1.9440,  2.5691],\n",
      "        [ 1.6309,  1.1922, -1.0231]]), loss 0.7038593292236328\n",
      "epoch  900/1000, batch 2, prediction tensor([[ 2.3410,  2.1347, -2.9410],\n",
      "        [-2.1324, -0.3377,  2.8581]]), loss 0.3223712742328644\n",
      "epoch  900/1000, batch 3, prediction tensor([[ 1.9102,  2.6461, -3.7016],\n",
      "        [-4.2946,  2.3597,  1.9158]]), loss 0.4444925785064697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  920/1000, batch 0, prediction tensor([[-4.4047,  2.5845,  1.8011],\n",
      "        [-2.1202, -0.3507,  2.8588]]), loss 0.2115396410226822\n",
      "epoch  920/1000, batch 1, prediction tensor([[ 3.4386,  2.6973, -4.3169],\n",
      "        [-2.2895,  0.3464,  1.5898]]), loss 0.32965168356895447\n",
      "epoch  920/1000, batch 2, prediction tensor([[ 1.6935,  1.2392, -1.1328],\n",
      "        [-4.0910,  2.0218,  2.5164]]), loss 0.7292200326919556\n",
      "epoch  920/1000, batch 3, prediction tensor([[ 1.7796,  2.9022, -3.8272],\n",
      "        [ 2.4170,  2.1925, -3.0747]]), loss 0.4360654652118683\n",
      "epoch  940/1000, batch 0, prediction tensor([[ 1.5363,  1.3120, -1.0484],\n",
      "        [-4.2162,  2.0410,  2.6225]]), loss 0.6487201452255249\n",
      "epoch  940/1000, batch 1, prediction tensor([[-2.3832,  0.3140,  1.7160],\n",
      "        [ 3.1867,  2.7268, -4.0945]]), loss 0.36152541637420654\n",
      "epoch  940/1000, batch 2, prediction tensor([[-4.4236,  2.4331,  1.9713],\n",
      "        [-2.1566, -0.3866,  2.9311]]), loss 0.265424519777298\n",
      "epoch  940/1000, batch 3, prediction tensor([[ 1.8715,  2.8303, -3.8472],\n",
      "        [ 2.5429,  2.0857, -3.0939]]), loss 0.4090334475040436\n",
      "epoch  960/1000, batch 0, prediction tensor([[ 1.8725,  2.8730, -3.8908],\n",
      "        [-2.1819, -0.3543,  2.9241]]), loss 0.17838440835475922\n",
      "epoch  960/1000, batch 1, prediction tensor([[-4.5553,  2.6952,  1.8410],\n",
      "        [-2.3582,  0.3314,  1.6736]]), loss 0.30060499906539917\n",
      "epoch  960/1000, batch 2, prediction tensor([[ 1.4159,  1.5271, -1.1430],\n",
      "        [ 3.3767,  2.7730, -4.3308]]), loss 0.5557225942611694\n",
      "epoch  960/1000, batch 3, prediction tensor([[-4.3426,  2.2155,  2.5744],\n",
      "        [ 2.4458,  2.3086, -3.2197]]), loss 0.5794934630393982\n",
      "epoch  980/1000, batch 0, prediction tensor([[ 3.5774,  2.5016, -4.2600],\n",
      "        [-2.3165,  0.2608,  1.7025]]), loss 0.2602403163909912\n",
      "epoch  980/1000, batch 1, prediction tensor([[ 2.7838,  1.8455, -3.0946],\n",
      "        [ 2.0239,  2.6832, -3.8524]]), loss 0.3750286400318146\n",
      "epoch  980/1000, batch 2, prediction tensor([[-4.3889,  2.4473,  1.9225],\n",
      "        [ 1.7328,  1.1047, -1.0375]]), loss 0.7806037664413452\n",
      "epoch  980/1000, batch 3, prediction tensor([[-2.2384, -0.3110,  2.9373],\n",
      "        [-4.3866,  2.2277,  2.6061]]), loss 0.28290754556655884\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, xy in enumerate(dataloader):\n",
    "        x_train, y_train = xy\n",
    "        prediction = model(x_train)\n",
    "        loss = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print('epoch {:4d}/{}, batch {}, prediction {}, loss {}'.format(\n",
    "                epoch, epochs, batch_idx, prediction.detach().squeeze(), loss\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-4.2512, -0.4969,  4.0222, -1.4844],\n",
      "        [ 0.7138, -0.0418, -0.7892,  1.5441],\n",
      "        [ 3.5629,  0.9892, -2.9965, -0.2744]], requires_grad=True), Parameter containing:\n",
      "tensor([-3.2445, -1.3347,  4.5795], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = list(model.parameters())[0] @ x[1].T+ list(model.parameters())[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7817, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.forward(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7932,  3.0198, -3.9583],\n",
      "        [ 1.3770,  1.5536, -1.1306]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
